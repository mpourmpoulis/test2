Κίτσιος Παναγιώτης
03116007


Αλγόριθμοι 3η Γραπτή


# exercise 2

without loss of generality, arbitrarily route the tree from any given node R0. Let us denote with d(u,v) the total weight of the single path leading from the root to a given node u, endpoints included, that is

```
d(u,v) = w(v) + ... + w(u)
```

for any given pair of nodes u and v, if we denote with r their lowest common ancestor(LCA), then it holds:
```
d(u,v) = d(u,r) + d(v,r) - w(r)
```

and as a consequence, our task is to compute:
```
max{u,v}(d(u,r) + d(v,r) - w(r) | where r is the lowest common ancestor of u,v)
```

Of course computing for every combination of nodes, results in a at least quadratic algorithm! working on this issue we observed that our problem can also be written in the form:
```
max{r}(
	max{u,v}(
		d(u,r) + d(v,r) - w(r) | where u,v are  such that r is the lowest common ancestor of u,v
	)
)
```
Please note that r can also be one of the two nodes u,v if for instance u is ancestor of v, but if he does not, then those two notes must belong to different subtrees! as a consequence, would not have to try combinations of nodes that belong to the same subtree and even more importantly,  so we have three options:

- u==v==r

- u==r and v is child of r

- u,v in different subtrees

If we  denote 
```
D(r) = max{u belongs to the subtree defined by r, including r}(d(u,r))
```


so we have
```
max{r}(
	D(r),
	max{t1,t2 are a subtree/child of r}(
		max{u1,u2 belong_to t1,t2}(
			d(u,r) + d(v,r) - w(r)
		)
	)
)
```

In thinking they leave will be greedily:
```
max{r}(
	D(r),
	max{t1,t2 are a subtree/child of r}(
		D(t1) + D(t2) + w(r)
	)
)
```

Finally noting that 
```
D(r) = max(
	max{t subtree of r}(D(t) + w(r)),
	w(r)
)
```

we arrive at the recursion
```
max{r}(
	w(r),
	max{t subtree of r}(D(t) + w(r)),
	max{t1,t2 are a subtree/child of r}(
		D(t1) + D(t2) + w(r)
	)
)
```

which can naturally be implemented using a depth first search!we keep track of the best path so far,  and before exiting a node, we perform the above computation , update if necessary and also pass that D(r) value to the parent node. so it is more open bottom up approach, but of course rounds in linear time:)






# exercise 5 bottleneck costs


a) were going to prove this by contradiction. Suppose that there are a pair of nodes u,v for which there exists a path p_other with a lower bottleneck cost than the one in the minimum spanning tree p_mst. As a consequence the heaviest edge of p_mst, let's name it e:

- can not be a part of p_other as

```
cost(p_other)<cost(p_mst) = l(e)
```

- Bridges a cut C, which leaves u,v on separate sides

on the other path must also connect  those two nodes, it must contain an edge e2 which all show bridges these cut

However, because corresponding country is minimum  and  e,e2 bridge the same cut, it must hold

```
l(e2)>=l(e)>cost(p_other)
```

Which is of course a contradiction,as it must hold
```
l(e2)<=cost(p_other)
```

if e2 in p_other!



b) A naïve approach to address this issue, would be to compute the minimum spanning tree and using it ,all the costs for every combination of nodes, which is of course at least quadratic. instead, our approach is going to be calculated for every edge, the number of bonds for which it is a bottleneck edge. We can then simply multiply its weight with this number and sum over all edges in the minimum spanning tree. 

to do that, we are going to use a little bit mortified version of Kruskal algorithm. Essentially what happens is that when our algorithm adds an edge to the meeting spanning tree, it is connecting to connected components with size n1 and n2, creating 

```
n1*n2
```
paths which correspond to every combination often notes from the one component with the other as origin destination pairs,contributing

```
n1*n2*l(e)
```


The values of n1,n2 are already stored by the union find, so the extra complexity is just O(n), which of course can be ignored when compared to O(mlogm) of the standard Kruskal algorithm.


to prove the validity of this algorithm, we need to prove the following three points

- we are not forgetting any path

- We are not double counting any path

- For each path we truly find its bottleneck cost


let's go over each of them

* Our algorithm starts with every node being an connected component and in the end we have on connected component containing all nodes. as a consequence, for every pair of nodes there must have been a iteration of the start of which, they belong to different connected components and at the end of which they were joined in the same connected component. During the duration their path was counted, so we cannot be forgetting any paths.

* Furthermore, our algorithm counts paths between two nodes, only when they belong to different connected components and those connected components get merged, which of course happens only once so we cannot double count any path!

* Because Kruskal adds edges to the tree with increasing weight order, each of the path created cannot have any edge heavier then the one we are currently adding to the tree, so the bottleneck cost cannot be higher than l(e). Furthermore, it cannot be lower, because otherwise there would have to be other edge with a lower weight which bridges the same cut as the one who just added! as a consequence, for every pair of notes we are correctly computing the Bartlett cost of the path between them.

and we are done!



# exercise three (MST)

a) obvious counterexample 

origin|destination|weight
------|-----------|------
1|2|3
1|3|4
1|4|5
2|4|100
2|3|1

The greedy algorithm produces a tree with the following edges (1,2),(1,3),(2,4) with the cost of 107

The optimal tree has edges (1,2),(1,4),(2,3) with the cost of 9!



b) 
we propose the following algorithm

* Constructing minimum spanning tree using Kruskal algorithm and union find, and  we are going to maintain the tree structure

* for every edging the graph

	- locate its endpoints in the tree , and moving upwards find the edge that made them merge into a single connected component

	- Declare these edge, as a potential replacement

	- Only keep track for each edge of the MST of the best replacement produced by the above step and also maintain information ,for every edge with one of its two endpoints being the  node specified by the problem about, which edges should be replaced, should we choose to add to the tree.

	- the whole operation for each edge can be performed in atmost O(logn) ,so we get time complexity of O(mlogn)


* In order for the specified node to have a given cardinality, we may perform one of the two actions

	- add edge adjacent to it to the MST, removing the one which breeds the same cuts in which we have already determined from the previous operation. The cost of such an operation  is `w(e_adjacent)-w(e_removed)`

	- Removing an edge adjacent to it from the MST, The cost of such an operation  is 
	`w(e_best_replacement) - w(e_adjacent)` if a replacement exists, or infinite  instead

* if the cardinality of an old in the minimum spanning tree is less than desired one, we only need two beautiful additions, otherwise we only need to perform deletions. With that established, we generate all possible actions which are only linear with respect to the cardinality of the node in the tree so what most O(n) and we sort them for a total complexity of O(nlogn). because any action we take removes/introduces edges that the bridge different cuts ( so there is no overlap between the actions) we can simply pick up greedily only the cheapest necessary `|k-cardinality_mst|` action.

### important technicalities

Now there's an important technicality, the assumption presented in the statement of the problem namely that a spanning tree with a given node s having a specific cardinality k does not hold! an obvious counterexample to that claim is a graph in the shape of a star. If I for instance want the center node to have a cardinality of two and it has five children then that is of course impossible. 

So to make sure, everything works properly we also need to check that the final cost of the tree  produced by our algorithm is not infinite which would (only) happen if we removed an edge that cannot be removed

### proof of correctness

one of the first things we must make sure is that the result of algorithm does not depend on the choice of the minimum spanning tree in case there are ties. now suppose that there are two minimum spanning trees t1,t2 . Then for each edge

```
e1 belongs t1  and not belongs t2
```
there must be an edge

```
e2 belongs t2  and not belongs t1
```

with  `w(e1)==w(e2)` that bridge the same cuts!

As a consequence,if on the first tree it is possible to replace e1 with e3, then running on the second tree it it would also be possible to replace e2 with e3 because e3 must be bridging the same cuts as e1 and consequently as e2. And of course these replacement would have the same cost because `w(e1)==w(e2)`

so all result is invariant with respect to tie-breaking MST 

moving on, we observe that 


we are going to make the following assumption,



# exercise four (Boruvka)


a) given that upon termination, there is just one connected component containing every node, to show that is spanning tree of the original graph it suffices to show that it does not contain any cycles. we will do this by contradiction. 

Suppose that graph contains a cycle. Because edges can only be added to the result only if at some iteration  their two endpoints below moved to different connect components, it follows that some iteration some edges e1,e2,...,eN were added to the result connecting components C1 to C2,...,CN to C1. 


However, because both e1 and e2 are outgoing with respect to C2, since C2 chose e2, it must follow

```
w(e2)<w(e1)
```
(the weight mentioned above is out there we have done tie-breaking)

And applying the same logic to all connected components

```
w(e1)<w(eN)<...<w(e2)<w(e1)
```

Which of course a contradiction!

so the algorithm does produce spanning tree,it is time show is also minimum. Consider any Connected component


c) with Fibonacci heap, Prim algorithm runs in time `O(m + nlogn)` 

so we can see that it performs very well when graph are dense.

we also notice, that Boruvka algorithm achieved dramatic degrees in the number of connected components in its beginning stages, for instance during the first stage these number is reduced from  n to less than n/2 with the a cost of only O(m), whereas it loses steam towards the end. So a quick idea is to combine them, let Boruvka run first and drastically reduce the number of components, something at which it excels, and when there are only a few nodes/connected components left in the graph is dense, let Prim debulk what is left. the question is how long do we wait before switching algorithm?


if we let it for log(logn) rounds then when the second algorithm takes on there would be at most n/logn nodes and we obtain a total cost of

```
O(mlog(logn) + m + (n/logn)* log(n/logn))

O(mlog(logn) + (n/logn)* log(n/logn))

O(mlog(logn) + (n/logn)* log(n))

O(mlog(logn) + n)

O(mlog(logn))
```



# Exercise One 


We model the problem is a direct graph where each node corresponds to each box and there is an edge between two boxes if and only if it is possible that this destination box with the keys inside the origin box. then  denote 

```
reachable(x) =  {y  for y in V if path exists from  x to y}
```
 and 

```
loop(x) = {y for y in V if path exists from x to y  and  from  y to x}
```

if we can open a box one way or another, then we are able to open without using the hammer at all and any box can be opened with keys contained in the boxes we can open from the keyes retrieved from the current box and so on. So effectively if we can open x we can also open reachable(x)


so our problem simply comes down to computing

```
argmin
{S = {s1,s2,...,sN} , S is subset of V, reachable(s1) union reachable(s2) .... union reachable(sN) == V}
(|S|)
```

reachable end loop can be easily computed for every node using the depth first search (or even BFS, we just need to make sure that when we  finder cycle bike to the original node that we annotate every node in the cycle). 



using this and the obvious fact that

```
if y in reachable(x):
	reachable(y) subset of reachable(x)
```

which hold simply because 

```
if exists x->y and exists y->z:
	exists x->z
```


We devised the following linear time algorithm 

```
initialize S=V 

Mark all nodes as non-visited

While there are still nodes are not visited:

* chose a starting note  x 

* start a DFS from it 

* when we find an node v that is not visited, mark it visited , remove it from S and mark it covered from x, origin[v]=x 

* Furthermore Mark if it belongs to loop(x)

* If we tried to visit a node v but could not as it is already visited, if it is a loop node with respect to each origin y , remove y from S in the mark it visit. please note that of course x does not belong to reachable(y)!


When done right down the remaining set S
```

to prove the validity of all our algorithm we must show that

* `S is subset of V, reachable(s1) union reachable(s2) .... union reachable(sN) == V` holds

* And that there isn't a  set with smaller cardinality for which the previous condition holds

The first condition is of course met because at the end of the the algorithm always nodes have been visited and does a consequence are reachable from at least one node in S(even if it is themselves)!


to prove the second condition, suppose there was a set with smaller cardinality. Then there must be at least one node s in the original set S that does not belong to the smaller one S2. for this to be possible there must be another node y for which it would hold

```
s belongs to reachable(y)
```

and because of the optimality of that S2 H would also hold

```
x does not belong to reachable(y) for x in S2 if x!=y
```

( otherwise we could remove x as well )

However these has a very important implication. Because when our algorithm was run, s was never removed from the original set, means that it was never visited  from a DFS started from another node. as a consequence it must hold

```
y belongs to reachable(x) -> y belongs to loop(x)
```

and it does not belong to S. as a consequence   elements of S are also part of S2 can be at most `|S|-2`, so there must also be a second missing.  but the same logic will also apply for it, so there must be a third missing and so on until we run out of nodes. Essentially our argument is that for every note we remove, we must add a replacement and because of the previously mentioned


```
x does not belong to reachable(y) for x in S2 if x!=y
```

These replacements must be unique! so we arrive at the contradiction and it must hold

`|S2|>=|S|`

our second condition has now been proven and we thought the validity of all our algorithm!


